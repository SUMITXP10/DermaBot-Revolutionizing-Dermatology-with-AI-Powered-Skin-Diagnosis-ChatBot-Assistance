{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8259de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd19d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract image features using Multi-feature Fusion Algorithm\n",
    "def extract_features(frame):\n",
    "    # Ensure that the frame is a valid image\n",
    "    if frame is None or len(frame.shape) != 3:\n",
    "        raise ValueError(f\"Invalid input frame: {frame}\")\n",
    "\n",
    "    # Convert the frame to HSV color space\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Calculate 2D histogram in HSV color space\n",
    "    hsv_hist = cv2.calcHist([hsv_frame], [0, 1], None, [256, 256], [0, 256, 0, 256])\n",
    "\n",
    "    # Normalize the histogram\n",
    "    hsv_hist = cv2.normalize(hsv_hist, hsv_hist).flatten()\n",
    "\n",
    "    return hsv_hist\n",
    "\n",
    "# Function to calculate cosine similarity between frames\n",
    "def calculate_similarity(frame1, frame2):\n",
    "    features1 = extract_features(frame1)\n",
    "    features2 = extract_features(frame2)\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Function to apply Graph Modularity Clustering Algorithm\n",
    "def modularity_clustering(graph):\n",
    "    spectral = SpectralClustering(n_clusters=2, affinity='nearest_neighbors', random_state=42)\n",
    "    labels = spectral.fit_predict(nx.to_numpy_array(graph))\n",
    "    return labels\n",
    "\n",
    "# Function to apply skin image processing using ResNet-50\n",
    "def skin_image_processing(image_path):\n",
    "    # Implement your skin image processing using ResNet-50 here\n",
    "    # Placeholder: Using a simple transformation for demonstration\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    \n",
    "    # Load pre-trained ResNet-50 model\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.eval()\n",
    "    \n",
    "    # Placeholder: Forward pass through ResNet-50\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "\n",
    "    # Placeholder: Extracting predicted class, replace with your logic\n",
    "    predicted_class = torch.argmax(output).item()\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# Function to load metadata from CSV\n",
    "def load_metadata(metadata_path):\n",
    "    return pd.read_csv(metadata_path)\n",
    "\n",
    "# Function to display image with metadata\n",
    "def display_image_with_metadata(image_path, metadata):\n",
    "    # Print image path and metadata information\n",
    "    print(f\"Image Path: {image_path}\")\n",
    "    print(\"Metadata:\")\n",
    "    print(metadata)\n",
    "    \n",
    "    # You can also add code here to display the image using a library like OpenCV or PIL\n",
    "    # For example, to display an image using OpenCV:\n",
    "    image = cv2.imread(image_path)\n",
    "    cv2.imshow(\"Image with Metadata\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to process video and integrate with HAM10000 dataset\n",
    "def process_video(video_path, dataset_path, metadata_path, output_directory):\n",
    "    # Initialize variables\n",
    "    keyframes = []\n",
    "    graph = nx.Graph()\n",
    "    clusters = []\n",
    "\n",
    "    # Load metadata from HAM10000 dataset\n",
    "    metadata = load_metadata(metadata_path)\n",
    "\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Check if the video file is successfully opened\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open the video file.\")\n",
    "        return\n",
    "\n",
    "    # Create directories to store processed frames and keyframes\n",
    "    processed_frames_dir = os.path.join(output_directory, \"processed_frames\")\n",
    "    keyframes_dir = os.path.join(output_directory, \"keyframes\")\n",
    "\n",
    "    os.makedirs(processed_frames_dir, exist_ok=True)\n",
    "    os.makedirs(keyframes_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through each frame in the video\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            # Extract features and add frame to the graph\n",
    "            features = extract_features(frame)\n",
    "            graph.add_node(len(graph), frame=frame, features=features)\n",
    "\n",
    "            # Save processed frame\n",
    "            frame_filename = f\"{len(graph)}.jpg\"\n",
    "            frame_path = os.path.join(processed_frames_dir, frame_filename)\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing frame: {e}\")\n",
    "\n",
    "    # Calculate similarity between frames and add edges to the graph\n",
    "    for i in range(len(graph)):\n",
    "        for j in range(i + 1, len(graph)):\n",
    "            similarity = calculate_similarity(graph.nodes[i]['frame'], graph.nodes[j]['frame'])\n",
    "            graph.add_edge(i, j, weight=similarity)\n",
    "\n",
    "    # Apply Graph Modularity Clustering Algorithm\n",
    "    labels = modularity_clustering(graph)\n",
    "\n",
    "    # Identify clusters based on modularity scores\n",
    "    for cluster_id in np.unique(labels):\n",
    "        cluster_nodes = np.where(labels == cluster_id)[0]\n",
    "        cluster = graph.subgraph(cluster_nodes)\n",
    "        clusters.append(cluster)\n",
    "\n",
    "    # Select keyframes from each cluster based on quality metrics\n",
    "    for cluster in clusters:\n",
    "        avg_quality_scores = []\n",
    "        for node in cluster.nodes():\n",
    "            # Ensure 'features' key is present in all nodes\n",
    "            if 'features' not in graph.nodes[node]:\n",
    "                graph.nodes[node]['features'] = np.zeros(256 * 256)  # Placeholder: Use appropriate size\n",
    "\n",
    "            # Placeholder: Implement your own quality metric calculation\n",
    "            quality_score = np.mean(graph.nodes[node]['features'])\n",
    "            avg_quality_scores.append(quality_score)\n",
    "\n",
    "        # Select the frame with the highest quality based on quality metrics\n",
    "        keyframe_index = np.argmax(avg_quality_scores)\n",
    "        keyframes.append(keyframe_index)\n",
    "\n",
    "        # Save keyframe\n",
    "        keyframe_filename = f\"{keyframe_index}.jpg\"\n",
    "        keyframe_path = os.path.join(keyframes_dir, keyframe_filename)\n",
    "        cv2.imwrite(keyframe_path, graph.nodes[keyframe_index]['frame'])\n",
    "\n",
    "    # Close video file\n",
    "    cap.release()\n",
    "\n",
    "    # Process selected keyframes\n",
    "    for keyframe_index in keyframes:\n",
    "        keyframe_path = os.path.join(output_directory, \"keyframes\", f\"{keyframe_index}.jpg\")\n",
    "\n",
    "        # Apply skin image processing using ResNet-50\n",
    "        skin_condition = skin_image_processing(keyframe_path)\n",
    "\n",
    "        # Display the result\n",
    "        display_image_with_metadata(keyframe_path, metadata.iloc[keyframe_index])\n",
    "        print(f\"Skin Condition: {skin_condition}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0221f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumit\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_spectral.py:688: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sumit\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sumit\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sumit\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Path: C:\\Users\\Sumit\\Desktop\\Smart India Hackathon 2023\\Backend Deployment Files Repo\\ISIC-images\\output\\keyframes\\162.jpg\n",
      "Metadata:\n",
      "isic_id                                                        ISIC_0024468\n",
      "attribution               ViDIR Group, Department of Dermatology, Medica...\n",
      "copyright_license                                                  CC-BY-NC\n",
      "age_approx                                                             75.0\n",
      "anatom_site_general                                               head/neck\n",
      "benign_malignant                                                        NaN\n",
      "diagnosis                                                 actinic keratosis\n",
      "diagnosis_confirm_type                                       histopathology\n",
      "image_type                                                      dermoscopic\n",
      "lesion_id                                                        IL_6302381\n",
      "melanocytic                                                           False\n",
      "sex                                                                    male\n",
      "Name: 162, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Set the paths and call the main function\n",
    "video_path = r\"C:\\Users\\Sumit\\Desktop\\Smart India Hackathon 2023\\Backend Deployment Files Repo\\Test_skin_video_sample_01.mp4\"\n",
    "dataset_path = r\"C:\\Users\\Sumit\\Desktop\\Smart India Hackathon 2023\\Backend Deployment Files Repo\\ISIC-images\"\n",
    "metadata_path = r\"C:\\Users\\Sumit\\Desktop\\Smart India Hackathon 2023\\Backend Deployment Files Repo\\metadata.csv\"\n",
    "output_directory = r\"C:\\Users\\Sumit\\Desktop\\Smart India Hackathon 2023\\Backend Deployment Files Repo\\ISIC-images\\output\"\n",
    "\n",
    "process_video(video_path, dataset_path, metadata_path, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
