{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yonUJdA-kwEv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tqdm.auto import tqdm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import speech_recognition as sr\n",
        "from gtts import gTTS\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uu_ZbuqBCETJ"
      },
      "outputs": [],
      "source": [
        "data_dir=r'C:\\Users\\hp\\Desktop\\SIH\\skin_disease_sih\\training\\train_set'\n",
        "# data = pd.read_csv(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OQxg8V_8z9k",
        "outputId": "70dc888b-d751-4677-ab67-715dff6b1425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 824 files belonging to 7 classes.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 660 files for training.\n"
          ]
        }
      ],
      "source": [
        "img_height,img_width=224,224\n",
        "batch_size=32\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs49Bg_OFdOI",
        "outputId": "3afe3100-4303-4f29-92a9-df1e5a9a8006"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbNQsnLVlvoF",
        "outputId": "e94e2a5a-d209-44dc-efbe-866d009291e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 824 files belonging to 7 classes.\n",
            "Using 164 files for validation.\n"
          ]
        }
      ],
      "source": [
        "img_height,img_width=224,224\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3j38LKi8_XB",
        "outputId": "bc614fc1-f2b4-4342-ff42-c1c8cded0865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['BA- cellulitis', 'BA-impetigo', 'FU-athlete-foot', 'FU-nail-fungus', 'FU-ringworm', 'VI-chickenpox', 'VI-shingles']\n"
          ]
        }
      ],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "learning_control = ReduceLROnPlateau(monitor = 'val_acc' , patience=3 , verbose = 1 , factor = 0.5 , lr = 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojWaRtpDmAX5",
        "outputId": "c28d12f4-51f9-47a2-d327-6e8e42d8ef19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# resnet_model = Sequential()\n",
        "\n",
        "# pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "#                    input_shape=(180,180,3),\n",
        "#                    pooling='avg',classes=7,\n",
        "#                    weights='imagenet')\n",
        "# for layer in pretrained_model.layers:\n",
        "#         layer.trainable=False\n",
        "\n",
        "# resnet_model.add(pretrained_model)\n",
        "# resnet_model.add(Flatten())\n",
        "# resnet_model.add(Dense(128, activation='relu'))\n",
        "# resnet_model.add(Dense(64,activation='relu'))\n",
        "# resnet_model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model = tf.keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3),\n",
        "    pooling='avg',\n",
        "    classes=7,  # Ensure this matches the number of classes in your task\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(128, activation='relu'))\n",
        "resnet_model.add(Dense(64, activation='relu'))\n",
        "resnet_model.add(Dense(7, activation='softmax'))  # Change the units to match the number of classes\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sgd = SGD(lr = 0.01 , clipvalue = 0.5)\n",
        "resnet_model.compile(optimizer = sgd , loss=\"categorical_crossentropy\" , metrics =[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZnDzlMG3mLcO"
      },
      "outputs": [],
      "source": [
        "# resnet_model.compile(optimizer='Adam'(learning_rate=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# # Define the optimizer with the learning rate\n",
        "# optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "# # Compile the model using the defined optimizer\n",
        "# resnet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the optimizer with the learning rate\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "# Compile the model using the defined optimizer\n",
        "resnet_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzD0GyH0mQMm",
        "outputId": "af2bfbd1-ffb1-4650-bbb4-080cf5e8933c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " module_wrapper (ModuleWrap  (None, 2048)              0         \n",
            " per)                                                            \n",
            "                                                                 \n",
            " module_wrapper_1 (ModuleWr  (None, 128)               262272    \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_2 (ModuleWr  (None, 64)                8256      \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_3 (ModuleWr  (None, 7)                 455       \n",
            " apper)                                                          \n",
            "                                                                 \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================================================\n",
            "Total params: 23858695 (91.01 MB)\n",
            "Trainable params: 270983 (1.03 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the EarlyStopping callback\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNAh4h7DmToj",
        "outputId": "692df999-8ca9-4bc9-b707-e5966e241f9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "21/21 [==============================] - 51s 2s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9756\n",
            "Epoch 2/10\n",
            "21/21 [==============================] - 42s 2s/step - loss: 8.7873e-04 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9756\n",
            "Epoch 3/10\n",
            "21/21 [==============================] - 46s 2s/step - loss: 7.8531e-04 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9756\n",
            "Epoch 4/10\n",
            "21/21 [==============================] - 47s 2s/step - loss: 6.8963e-04 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9756\n",
            "Epoch 5/10\n",
            "21/21 [==============================] - 43s 2s/step - loss: 6.1368e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9756\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "history = resnet_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    batch_size = 32,\n",
        "    epochs=epochs,\n",
        "    callbacks = [early_stop]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from flask import Flask, jsonify, request\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load your pre-trained model\n",
        "model = tf.keras.models.load_model('modelsih.h5')\n",
        "\n",
        "# Example endpoint for prediction\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json()  # Get data from POST request\n",
        "    # Process the data as needed (e.g., convert to numpy array)\n",
        "    input_data = np.array(data['input'])\n",
        "    \n",
        "    # Make predictions using the loaded model\n",
        "    # predictions = model.predict(input_data)\n",
        "    \n",
        "    # Return predictions as JSON\n",
        "    return jsonify({'predictions': resnet_model.predict(img_array).tolist()})  # Convert predictions to JSON\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)  # Run the Flask app\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "ename": "NotImplementedError",
          "evalue": "\nLayer ModuleWrapper was created by passing\nnon-serializable argument values in `__init__()`,\nand therefore the layer must override `get_config()` in\norder to be serializable. Please implement `get_config()`.\n\nExample:\n\nclass CustomLayer(keras.layers.Layer):\n    def __init__(self, arg1, arg2, **kwargs):\n        super().__init__(**kwargs)\n        self.arg1 = arg1\n        self.arg2 = arg2\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"arg1\": self.arg1,\n            \"arg2\": self.arg2,\n        })\n        return config",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# from tensorflow.keras.models import load_model, save_model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming 'model' is your pretrained model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mresnet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpretrained_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# resnet_model.save_weights('pretrained_weights.h5')\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:825\u001b[0m, in \u001b[0;36mLayer.get_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    826\u001b[0m         textwrap\u001b[38;5;241m.\u001b[39mdedent(\n\u001b[0;32m    827\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was created by passing\u001b[39m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;124mnon-serializable argument values in `__init__()`,\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;124mand therefore the layer must override `get_config()` in\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;124morder to be serializable. Please implement `get_config()`.\u001b[39m\n\u001b[0;32m    832\u001b[0m \n\u001b[0;32m    833\u001b[0m \u001b[38;5;124mExample:\u001b[39m\n\u001b[0;32m    834\u001b[0m \n\u001b[0;32m    835\u001b[0m \u001b[38;5;124mclass CustomLayer(keras.layers.Layer):\u001b[39m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;124m    def __init__(self, arg1, arg2, **kwargs):\u001b[39m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;124m        super().__init__(**kwargs)\u001b[39m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;124m        self.arg1 = arg1\u001b[39m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;124m        self.arg2 = arg2\u001b[39m\n\u001b[0;32m    840\u001b[0m \n\u001b[0;32m    841\u001b[0m \u001b[38;5;124m    def get_config(self):\u001b[39m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;124m        config = super().get_config()\u001b[39m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;124m        config.update(\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: self.arg1,\u001b[39m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg2\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: self.arg2,\u001b[39m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;124m        return config\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         )\n\u001b[0;32m    849\u001b[0m     )\n",
            "\u001b[1;31mNotImplementedError\u001b[0m: \nLayer ModuleWrapper was created by passing\nnon-serializable argument values in `__init__()`,\nand therefore the layer must override `get_config()` in\norder to be serializable. Please implement `get_config()`.\n\nExample:\n\nclass CustomLayer(keras.layers.Layer):\n    def __init__(self, arg1, arg2, **kwargs):\n        super().__init__(**kwargs)\n        self.arg1 = arg1\n        self.arg2 = arg2\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"arg1\": self.arg1,\n            \"arg2\": self.arg2,\n        })\n        return config"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model, save_model\n",
        "\n",
        "# Assuming 'model' is your pretrained model\n",
        "resnet_model.save('pretrained_model.h5')\n",
        "# resnet_model.save_weights('pretrained_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import h5py\n",
        "\n",
        "# # Open the HDF5 file\n",
        "# with h5py.File('pretrained_model.h5', 'r') as file:\n",
        "#     # List all groups and datasets within the file\n",
        "#     def print_attrs(name, obj):\n",
        "#         print(name)\n",
        "#         for key, val in obj.attrs.items():\n",
        "#             print(f\"    {key}: {val}\")\n",
        "\n",
        "#     file.visititems(print_attrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def speak(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    tts.save(\"output1.mp3\")\n",
        "    os.system(\"mpg123 output1.mp3\")  # or use any other audio player suitable for your system\n",
        "speak(\"HELLO SIR , PLEASE CLICK THE BLUE BUTTON TO CLICK AN IMAGE OR RED BUTTON TO TAKE A  VIDEO\")\n",
        "img_path = r'C:\\Users\\hp\\Desktop\\SIH\\skin_disease_sih\\training\\train_set\\test_image.jpeg'  # Replace with your image file path\n",
        "\n",
        "def speak(text):\n",
        "    tts = gTTS(text=text, lang='hi')\n",
        "    tts.save(\"output2.mp3\")\n",
        "    os.system(\"mpg123 output2.mp3\") \n",
        "speak(\"thodi der wait kijiye\")\n",
        "img = image.load_img(img_path, target_size=(224, 224))  # Adjust target_size as needed for your model\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = preprocess_input(img_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ho4JtdlEmXbr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "[[9.4792180e-05 1.1248579e-03 1.9411850e-07 4.6054702e-05 9.9868172e-01\n",
            "  8.0003062e-08 5.2347259e-05]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.9986817"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arr = resnet_model.predict(img_array)\n",
        "print(arr)\n",
        "index_of_largest = np.argmax(arr)\n",
        "arr[0][index_of_largest]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The probability of the disease Ringworm  is  0.9986817\n"
          ]
        }
      ],
      "source": [
        "class_labels = ['Cellulitis', 'Impetigo', 'Athlete Foot', 'Nail Fungus', 'Ringworm' , 'Chickenpox', 'Shingles' ]\n",
        "print(\"The probability of the disease\",class_labels[index_of_largest] ,\" is \" , arr[0][index_of_largest])\n",
        "def speak(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    tts.save(\"output2.mp3\")\n",
        "    os.system(\"mpg123 output2.mp3\") \n",
        "speak(\"PLEASE WAIT FOR A WHILE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iQmVgLRCmeyd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 224, 224, 3)\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "[[3.5384217e-06 7.8786897e-08 4.6282933e-09 9.4208553e-06 9.9988794e-01\n",
            "  2.8019222e-09 9.8895529e-05]]\n",
            "The predicted class is FU-ringworm\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "image=cv2.imread(r'C:\\Users\\hp\\Desktop\\SIH\\skin_disease_sih\\training\\train_set\\test_image.jpeg')\n",
        "image_resized= cv2.resize(image, (img_height,img_width))\n",
        "image=np.expand_dims(image_resized,axis=0)\n",
        "print(image.shape)\n",
        "pred=resnet_model.predict(image)\n",
        "print(pred)\n",
        "output_class=class_names[np.argmax(pred)]\n",
        "print(\"The predicted class is\", output_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e1WKUQ5mivW"
      },
      "outputs": [],
      "source": [
        "# C:\\Users\\hp\\Desktop\\SIH\\skin_disease_sih\\training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Listening...\n",
            "User said: Sorry, I didn't understand that.\n",
            "Listening...\n",
            "User said: hello there mentor is a bitch their mentor is a bitch their mentor is a which there mentor is a bitch hey hello hello i don't understand\n",
            "Listening...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Main loop\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Get user's voice command\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser said:\u001b[39m\u001b[38;5;124m\"\u001b[39m, user_input)\n\u001b[0;32m     41\u001b[0m     response \u001b[38;5;241m=\u001b[39m process_command(user_input)  \u001b[38;5;66;03m# Process the command using your ML model\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[21], line 11\u001b[0m, in \u001b[0;36mlisten\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mListening...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m     recognizer\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)\n\u001b[1;32m---> 11\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio)\n",
            "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py:523\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    525\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
            "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# import speech_recognition as sr\n",
        "# from gtts import gTTS\n",
        "# import os\n",
        "\n",
        "# Function to recognize speech\n",
        "def listen():\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"Listening...\")\n",
        "        recognizer.adjust_for_ambient_noise(source)\n",
        "        audio = recognizer.listen(source)\n",
        "    \n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        return text.lower()  # Return the recognized text in lowercase\n",
        "    except sr.UnknownValueError:\n",
        "        return \"Sorry, I didn't understand that.\"\n",
        "    except sr.RequestError:\n",
        "        return \"Sorry, there was an error recognizing the speech.\"\n",
        "\n",
        "# Function to speak\n",
        "def speak(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    tts.save(\"output.mp3\")\n",
        "    os.system(\"mpg123 output.mp3\")  # or use any other audio player suitable for your system\n",
        "speak(\"The probability of the disease Ringworm  is  99.99918%\")\n",
        "# Your ML model to process the recognized text (replace this with your model integration)\n",
        "def process_command(command):\n",
        "    # Your model logic goes here\n",
        "    # Example:\n",
        "    if \"hello\" in command:\n",
        "        return \"Hi there!\"\n",
        "    else:\n",
        "        return \"Command not recognized.\"\n",
        "\n",
        "# Main loop\n",
        "while True:\n",
        "    user_input = listen()  # Get user's voice command\n",
        "    print(\"User said:\", user_input)\n",
        "    \n",
        "    response = process_command(user_input)  # Process the command using your ML model\n",
        "    \n",
        "    speak(response)  # Speak the response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Sequential' object has no attribute 'h5'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m resnet_model\u001b[38;5;241m.\u001b[39msave(\u001b[43mresnet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh5\u001b[49m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'h5'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 208 images belonging to 7 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_25736\\940447153.py:17: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  confidence_scores = model.predict_generator(test_generator)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.5235197e-02 1.4080690e-03 3.6288972e-03 ... 4.1197619e-01\n",
            "  5.3042453e-04 6.3429889e-03]\n",
            " [1.4146981e-02 1.4605016e-03 3.3801973e-03 ... 4.2742375e-01\n",
            "  5.3060672e-04 6.1629605e-03]\n",
            " [1.2745012e-02 1.1785305e-03 2.7713107e-03 ... 4.3474007e-01\n",
            "  4.1956609e-04 5.1961853e-03]\n",
            " ...\n",
            " [1.5081271e-02 1.6227755e-03 3.6844886e-03 ... 4.2829046e-01\n",
            "  5.8251451e-04 6.5011661e-03]\n",
            " [1.5050463e-02 1.6006541e-03 3.6874877e-03 ... 4.3010622e-01\n",
            "  5.6558434e-04 6.3350247e-03]\n",
            " [1.4282130e-02 1.5584549e-03 3.5180172e-03 ... 4.3903843e-01\n",
            "  5.3380587e-04 5.8330777e-03]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = resnet_model  # Load your trained Keras model\n",
        "image_height = 224\n",
        "\n",
        "# Define ImageDataGenerator for testing data\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)  # Normalize pixel values\n",
        "batch_size = 32\n",
        "# Load testing data from directory\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    r'C:\\Users\\hp\\Desktop\\SIH\\skin_disease_sih\\training\\test_set',\n",
        "    target_size=(image_height, image_height),  # Set image size as required\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Adjust based on your problem (e.g., 'binary', 'categorical')\n",
        "    shuffle=False  # Ensure the order is maintained for calculating confidence scores\n",
        ")\n",
        "\n",
        "# Predict on testing data and get confidence scores\n",
        "confidence_scores = model.predict_generator(test_generator)\n",
        "print(confidence_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'true_labels' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming predicted_labels and true_labels are available\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[43mtrue_labels\u001b[49m, predicted_labels)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'true_labels' is not defined"
          ]
        }
      ],
      "source": [
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # Assuming predicted_labels and true_labels are available\n",
        "# accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "# print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Sequential' object has no attribute 'hdf5'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[43mresnet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhdf5\u001b[49m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'hdf5'"
          ]
        }
      ],
      "source": [
        "# model.save(resnet_model.hdf5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
